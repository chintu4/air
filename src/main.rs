use anyhow::Result;
use clap::Parser;
use tracing::info;
use tracing_subscriber;
use std::io::{self, Write};

mod agent;
mod models;
mod providers;
mod config;
mod tools;

use agent::AIAgent;
use config::Config;

#[derive(Parser)]
#[command(name = "ruai")]
#[command(about = "AI Agent with local and cloud model fallback")]
struct Args {
    #[arg(short, long, help = "Input prompt for the AI")]
    prompt: Option<String>,
    
    #[arg(short, long, help = "Run in interactive mode")]
    interactive: bool,
    
    #[arg(short, long, help = "Force cloud model usage")]
    cloud_only: bool,
    
    #[arg(short, long, help = "Force local model usage")]
    local_only: bool,
    
    #[arg(long, help = "Pure local model response without templates")]
    local: bool,
    
    #[arg(short, long, help = "Verbose output")]
    verbose: bool,
}

#[derive(Debug, Clone)]
enum QueryMode {
    Auto,       // Smart fallback (default)
    LocalOnly,  // Force local model
    CloudOnly,  // Force cloud model
    PureLocal,  // Pure local model without templates
}

#[tokio::main]
async fn main() -> Result<()> {
    // Load environment variables from .env file
    dotenv::dotenv().ok();
    
    let args = Args::parse();
    
    // Initialize logging
    let subscriber = tracing_subscriber::fmt()
        .with_max_level(if args.verbose { 
            tracing::Level::DEBUG 
        } else { 
            tracing::Level::INFO 
        })
        .finish();
    tracing::subscriber::set_global_default(subscriber)?;

    info!("Starting RUAI Agent...");

    // Load configuration
    let config = Config::load()?;
    
    // Initialize AI Agent
    let agent = AIAgent::new(config).await?;
    
    // Check if we should run in interactive mode
    if args.interactive || args.prompt.is_none() {
        run_interactive_mode(agent, args).await?;
    } else {
        run_single_query(agent, args).await?;
    }
    
    Ok(())
}

async fn run_interactive_mode(agent: AIAgent, args: Args) -> Result<()> {
    // Initialize the query mode based on command line args
    let mut query_mode = if args.cloud_only {
        QueryMode::CloudOnly
    } else if args.local_only {
        QueryMode::LocalOnly
    } else if args.local {
        QueryMode::PureLocal
    } else {
        QueryMode::Auto
    };

    println!("\nğŸ¤– RUAI Interactive Mode");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!("ğŸ’¡ Type your questions and I'll help you!");
    println!("ğŸ”„ Current mode: {}", format_mode(&query_mode));
    println!("ğŸ“ Special commands:");
    println!("   â€¢ 'exit' or 'quit' - Exit the program");
    println!("   â€¢ 'help' - Show available commands");
    println!("   â€¢ 'stats' - Show usage statistics");
    println!("   â€¢ 'clear' - Clear the screen");
    println!("   â€¢ 'mode auto' - Smart fallback mode (default)");
    println!("   â€¢ 'mode local' - Force local model only");
    println!("   â€¢ 'mode cloud' - Force cloud model only");
    println!("   â€¢ 'mode pure' - Pure local model (no templates)");
    println!("   â€¢ 'mode status' - Show current mode");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    
    loop {
        // Display prompt
        print!("\nğŸ’¬ You: ");
        io::stdout().flush()?;
        
        // Read user input
        let mut input = String::new();
        match io::stdin().read_line(&mut input) {
            Ok(_) => {
                let query = input.trim().to_string();
                
                                // Handle special commands
                match query.trim().to_lowercase().as_str() {
                    "exit" | "quit" | "q" => {
                        println!("
ğŸ‘‹ Goodbye! Thanks for using RUAI!");
                        break;
                    }
                    "help" | "h" => {
                        show_help();
                        continue;
                    }
                    "stats" => {
                        show_stats(&agent).await?;
                        continue;
                    }
                    "clear" | "cls" => {
                        // Clear screen (works on both Windows and Unix)
                        print!("\x1B[2J\x1B[1;1H");
                        io::stdout().flush()?;
                        continue;
                    }
                    "mode status" => {
                        println!("
ğŸ”„ Current query mode: {}", format_mode(&query_mode));
                        continue;
                    }
                    "mode auto" => {
                        query_mode = QueryMode::Auto;
                        println!("
âœ… Switched to Auto mode (smart fallback: local first, then cloud)");
                        continue;
                    }
                    "mode local" => {
                        query_mode = QueryMode::LocalOnly;
                        println!("
ğŸ  Switched to Local-only mode");
                        continue;
                    }
                    "mode cloud" => {
                        query_mode = QueryMode::CloudOnly;
                        println!("
â˜ï¸  Switched to Cloud-only mode");
                        continue;
                    }
                    "mode pure" | "mode pure-local" => {
                        query_mode = QueryMode::PureLocal;
                        println!("
ğŸ”“ Switched to Pure Local mode (no templates or formatting)");
                        continue;
                    }
                    "" => {
                        println!("ğŸ’­ Please enter a question or command. Type 'help' for assistance.");
                        continue;
                    }
                    _ => {}
                }
                
                // Process the query
                println!("\nğŸ¤– RUAI: Processing your request... (Mode: {})", format_mode(&query_mode));
                
                match process_query_with_mode(&agent, &query, &query_mode).await {
                    Ok(response) => {
                        println!("\nğŸ¤– AI Response:");
                        println!("{}", response);
                    }
                    Err(e) => {
                        println!("\nâŒ Error: {}", e);
                        println!("ğŸ’¡ Try rephrasing your question or check your configuration.");
                    }
                }
            }
            Err(e) => {
                println!("\nâŒ Error reading input: {}", e);
                break;
            }
        }
    }
    
    Ok(())
}

async fn run_single_query(agent: AIAgent, args: Args) -> Result<()> {
    let prompt = args.prompt.as_ref().unwrap();
    
    // Process the request
    let response = process_query(&agent, prompt, &args).await?;
    
    println!("\nğŸ¤– AI Response:");
    println!("{}", response);
    
    Ok(())
}

async fn process_query(agent: &AIAgent, prompt: &str, args: &Args) -> Result<String> {
    let response = if args.cloud_only {
        agent.query_cloud_only(prompt).await?
    } else if args.local_only {
        agent.query_local_only(prompt).await?
    } else if args.local {
        agent.query_pure_local(prompt).await?
    } else {
        // Use the enhanced query with tools
        agent.query_with_tools(prompt).await?
    };
    
    // Format the response nicely
    Ok(format!("{}", response))
}

async fn process_query_with_mode(agent: &AIAgent, prompt: &str, mode: &QueryMode) -> Result<String> {
    let response = match mode {
        QueryMode::CloudOnly => agent.query_cloud_only(prompt).await?,
        QueryMode::LocalOnly => agent.query_local_only(prompt).await?,
        QueryMode::PureLocal => agent.query_pure_local(prompt).await?,
        QueryMode::Auto => agent.query_with_tools(prompt).await?,
    };
    
    // Format the response nicely
    Ok(format!("{}", response))
}

fn format_mode(mode: &QueryMode) -> String {
    match mode {
        QueryMode::Auto => "ğŸ”„ Auto (Smart Fallback)".to_string(),
        QueryMode::LocalOnly => "ğŸ  Local Only".to_string(),
        QueryMode::CloudOnly => "â˜ï¸  Cloud Only".to_string(),
        QueryMode::PureLocal => "ğŸ”“ Pure Local (No Templates)".to_string(),
    }
}

fn show_help() {
    println!("\nğŸ“š RUAI Help - Available Commands:");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!("ğŸ”¹ General Commands:");
    println!("   â€¢ exit, quit, q    - Exit the program");
    println!("   â€¢ help, h          - Show this help message");
    println!("   â€¢ stats            - Show usage statistics");
    println!("   â€¢ clear, cls       - Clear the screen");
    println!();
    println!("ğŸ”¹ Mode Control:");
    println!("   â€¢ mode auto        - Smart fallback mode (local first, then cloud)");
    println!("   â€¢ mode local       - Force local model only");
    println!("   â€¢ mode cloud       - Force cloud model only");
    println!("   â€¢ mode pure        - Pure local model (no templates or formatting)");
    println!("   â€¢ mode status      - Show current processing mode");
    println!();
    println!("ğŸ”¹ File System Operations:");
    println!("   â€¢ read file [path]          - Read and analyze a file");
    println!("   â€¢ write file [path]         - Get help creating a file");
    println!("   â€¢ list files                - Show project structure");
    println!("   â€¢ project structure         - Analyze directory tree");
    println!();
    println!("ğŸ”¹ Command Execution:");
    println!("   â€¢ run [command]             - Execute OS commands with permission");
    println!("   â€¢ execute [command]         - Run system commands safely");
    println!("   â€¢ git status                - Git commands (safe ones auto-approved)");
    println!("   â€¢ cargo build               - Rust development commands");
    println!("   â€¢ dir / ls                  - Directory listing");
    println!();
    println!("ğŸ”¹ Screenshot & Media:");
    println!("   â€¢ screenshot                - Take full screen capture");
    println!("   â€¢ screenshot region         - Capture specific screen region");
    println!("   â€¢ list screenshots          - Show saved screenshots");
    println!();
    println!("ğŸ”¹ Voice Commands:");
    println!("   â€¢ speak [text]              - Text-to-speech synthesis");
    println!("   â€¢ say [text]                - Generate speech from text");
    println!("   â€¢ listen                    - Speech-to-text recognition");
    println!();
    println!("ğŸ”¹ Web Operations:");
    println!("   â€¢ fetch [url]               - Download and analyze web pages");
    println!("   â€¢ web search [query]        - Search the web for information");
    println!("   â€¢ check [url]               - Check website status");
    println!();
    println!("ğŸ”¹ Development Tools:");
    println!("   â€¢ calculate [expression]    - Mathematical calculations");
    println!("   â€¢ remember [key] [value]    - Store information in memory");
    println!("   â€¢ recall [key]              - Retrieve stored information");
    println!("   â€¢ plan [goal]               - Create step-by-step plans");
    println!();
    println!("ğŸ’¡ Tips:");
    println!("   â€¢ You can ask natural questions - RUAI will detect when to use tools");
    println!("   â€¢ Commands are case-insensitive");
    println!("   â€¢ Auto mode tries local first for speed, then falls back to cloud");
    println!("   â€¢ Local mode is faster but may have limited capabilities");
    println!("   â€¢ Cloud mode provides better quality but uses API calls");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");

    println!("   â€¢ list voices               - Show available voices");
    println!();
    println!("ğŸ”¹ Query Examples:");
    println!("   â€¢ Math: '2+2', 'calculate 15*7'");
    println!("   â€¢ Programming: 'write a Python function', 'explain this code'");
    println!("   â€¢ Questions: 'explain AI', 'how does machine learning work'");
    println!("   â€¢ Creative: 'write a story', 'create a poem'");
    println!("   â€¢ Files: 'read file src/main.rs', 'analyze file config.toml'");
    println!();
    println!("ğŸ”¹ Web Operations:");
    println!("   â€¢ fetch [url]               - Download and analyze web pages");
    println!("   â€¢ web search [query]        - Search the web for information");
    println!("   â€¢ check [url]               - Check website status");
    println!();
    println!("ğŸ”¹ Development Tools:");
    println!("   â€¢ calculate [expression]    - Mathematical calculations");
    println!("   â€¢ remember [key] [value]    - Store information in memory");
    println!("   â€¢ recall [key]              - Retrieve stored information");
    println!("   â€¢ plan [goal]               - Create step-by-step plans");
    println!();
    println!("ï¿½ Tips:");
    println!("   â€¢ You can ask natural questions - RUAI will detect when to use tools");
    println!("   â€¢ Commands are case-insensitive");
    println!("   â€¢ Auto mode tries local first for speed, then falls back to cloud");
    println!("   â€¢ Local mode is faster but may have limited capabilities");
    println!("   â€¢ Cloud mode provides better quality but uses API calls");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
}

async fn show_stats(_agent: &AIAgent) -> Result<()> {
    println!("\nğŸ“Š RUAI Usage Statistics:");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    
    // This would require adding a get_stats method to AIAgent
    // For now, we'll show basic information
    println!("ğŸ  Local Model: Available");
    println!("â˜ï¸  Cloud Models: Check configuration");
    println!("âš¡ Status: Ready for queries");
    println!("ğŸ’¡ Tip: Use 'help' to see available commands");
    
    Ok(())
}
